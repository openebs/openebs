# test-network-failure.yml
# Author: Sudarshan
# Description: Include resiliency test suite in OpenEBS e2e (Test: periodic network failures)
- hosts: localhost
 
  vars_files: 
    - test-nw-failure-vars.yml 
 
  tasks:
   - block:

       ###################################################
       #                PREPARE FOR TEST                 #
       # (Place artifacts in kubemaster, start logger &  # 
       # confirm OpenEBS operator is ready for requests. #
       ###################################################

       - name: Get $HOME of K8s master for kubernetes user
         shell: source ~/.profile; echo $HOME
         args: 
           executable: /bin/bash
         register: result_kube_home
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       - name: Get percona spec and liveness scripts
         get_url:
           url: "{{ item }}"
           dest: "{{ result_kube_home.stdout }}"
         delegate_to: "{{ groups['kubernetes-kubemasters'].0 }}"
         with_items: "{{ percona_links }}"

       - name: Replace volume-claim name with test parameters
         replace:
           path: "{{ result_kube_home.stdout }}/percona.yaml"
           regexp: '{{ item.0 }}'
           replace: '{{ item.1 }}'
         delegate_to: "{{ groups['kubernetes-kubemasters'].0 }}"
         with_together:
           - "{{replace_item}}"
           - "{{replace_with}}"
         
       - name: Start the log aggregator to capture test pod logs
         shell: >
           source ~/.profile;
           nohup stern "{{test_pod_regex}}" --since 1m > "{{result_kube_home.stdout}}/{{test_log_path}}" &
         args:
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       - name: Check whether maya-apiserver pod is deployed
         shell: source ~/.profile; kubectl get pods | grep maya-apiserver
         args: 
           executable: /bin/bash
         register: result
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"    
         until: "'Running' in result.stdout"
         delay: 30 
         retries: 15
      
       ####################################################
       #          SETUP FAULT-INJECTION ENV               #
       # (Setup pumba deployment with an empty policy,    #
       # deploy percona w/ a liveness check for DB writes)# 
       ####################################################

       - name: Setup the pumba infrastructure
         shell: source ~/.profile; kubectl apply -f {{ pumba_file }}
         args:
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       - name: Confirm that the pumba deployment is running
         shell: source ~/.profile; kubectl get pods --no-headers -l app=pumba
         args:
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"
         register: result_pumba
         until: "'pumba' and 'Running' in result_pumba.stdout"
         delay: 30
         retries: 15

       - name: Create a configmap with the liveness sql script
         shell: source ~/.profile; kubectl create configmap sqltest --from-file={{ percona_files.1 }} 
         args: 
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"
         register: result 
         failed_when: "'configmap' and 'created' not in result.stdout"

       - name: Create percona deployment with OpenEBS storage
         shell: source ~/.profile; kubectl apply -f {{ percona_files.0 }}
         args:
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       - name: Wait for 120s to ensure liveness check starts 
         wait_for:
           timeout: 120
         
       - name: Confirm percona pod is running
         shell: source ~/.profile; kubectl get pods --no-headers -l name=percona   
         args: 
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"
         register: result
         until: "'percona' and 'Running' in result.stdout"
         delay: 30 
         retries: 15

       - name: Get the node details on which pvc-ctrl is scheduled 
         shell: kubectl get pods -o wide | grep ctrl | awk {'print $7'}
         args:
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"
         register: node_cntrl

       - name: Get the pvc-cntrl name
         shell: kubectl get pods | grep ctrl | awk {'print $1'}
         args:
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"
         register: pvc_cntrl_name

       - name: Get the cntrl container name
         shell: kubectl describe pod {{ pvc_cntrl_name.stdout }} | grep ctrl-con | awk {'print $1'}
         args:
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"
         register: con_name
               
       - name: Set container name to variable
         set_fact:
           container: "{{ con_name.stdout }}"        

       ########################################################
       #        INJECT FAULTS FOR SPECIFIED PERIOD            #
       # (Obtain begin marker before fault-inject(FI),do ctrl # 
       # failures, verify successful FI via end marker)       # 
       ########################################################

       - name: Get pumba container name
         shell: kubectl get pods -o wide | grep {{ node_cntrl.stdout }} | grep pumba | awk {'print $1'}
         args:
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"
         register: pumba_name

       - name: Initiate periodic network failures from pumba
         shell: > 
           kubectl exec {{ pumba_name.stdout }} -- pumba netem --interface eth0 
           --duration 1m delay --time {{ item }} re2:k8s_{{ container[:-1] }}; sleep 10
         args:
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"
         with_items: "{{ delay_interavals }}"

       ########################################################
       #        VERIFY RESILINCY/FAULT-TOLERATION             #
       # (Confirm liveness checks on percona are successful & #
       # pod is still in running state)                       #
       ########################################################

       - name: Confirm percona application is still running
         shell: source ~/.profile; kubectl get pods --no-headers -l name=percona   
         args: 
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"
         register: result
         until: "'percona' and 'Running' in result.stdout"
         delay: 30 
         retries: 15

       ########################################################
       #                        CLEANUP                       #			      
       # (Tear down application, liveness configmap as well as#
       # the FI (chaoskube) infrastructure. Also stop logger) # 
       ########################################################

       - name: Terminate the log aggregator
         shell: source ~/.profile; killall stern
         args:
           executable: /bin/bash 
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"  

       - set_fact:
           flag: "Pass"

     rescue: 
       - set_fact: 
           flag: "Fail"

     always:
       - include: test-nw-failure-cleanup.yml
         when: clean | bool

       - name: Send slack notification
         slack: 
           token: "{{ lookup('env','SLACK_TOKEN') }}"
           msg: '{{ ansible_date_time.time }} TEST: {{test_name}}, RESULT: {{ flag }}'
         when: slack_notify | bool and lookup('env','SLACK_TOKEN')

